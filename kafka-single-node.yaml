apiVersion: kafka.strimzi.io/v1beta2
kind: Kafka
metadata:
  name: single-node-cluster
spec:
  kafka:
    version: 2.8.0
    replicas: 1
    authorization:
      type: simple
      superUsers:
        - superuser
    listeners:
      - name: plain
        port: 9092
        type: internal
        tls: false
        authentication:
          type: scram-sha-512
      - name: tls
        port: 9093
        type: internal
        tls: true
        authentication:
          # type: tls
          type: scram-sha-512
      - name: external
        port: 9094
        type: route
        tls: true
        authentication:
          # type: tls
          type: scram-sha-512
    config:
      # specify the message format version the broker will use to append messages to the logs
      log.message.format.version: "2.8"
      inter.broker.protocol.version: "2.8"
      # default replication factors for automatically created topics
      default.replication.factor: 1
      # The default number of log partitions per topic
      num.partitions: 1
      # Enable auto creation of topic on the server
      auto.create.topics.enable: true
      # When a producer sets acks to "all" (or "-1"), min.insync.replicas specifies the minimum number of replicas that
      # must acknowledge a write for the write to be considered successful.
      # When used together, min.insync.replicas and acks allow you to enforce greater durability guarantees. A typical
      # scenario would be to create a topic with a replication factor of 3, set min.insync.replicas to 2, and
      # produce with acks of "all". This will ensure that the producer raises an exception if a
      # majority of replicas do not receive a write.
      min.insync.replicas: 1
      # The replication factor for the group metadata internal topics "__consumer_offsets" and "__transaction_state"
      # For anything other than development testing, a value greater than 1 is recommended for to ensure availability such as 3.
      offsets.topic.replication.factor: 1
      transaction.state.log.replication.factor: 1
      transaction.state.log.min.isr: 1
      # The minimum age of a log file to be eligible for deletion due to age. Default value: 168
      # The number of hours to keep a log file before deleting it (in hours), tertiary to log.retention.ms property
      log.retention.hours: 24
      # The default cleanup policy for segments beyond the retention window. A comma separated list of valid policies.
      # Valid policies are: "delete" and "compact". Default value: "delete"
      log.cleanup.policy: delete
      # Enable the log cleaner process to run on the server. Should be enabled if using any topics with a
      # cleanup.policy=compact including the internal offsets topic. If disabled those topics will not be compacted
      # and continually grow in size.
      log.cleaner.enable: true
      # How long are delete records retained?. Default value: 86400000 (24 hours)
      # 1 Hour
      log.cleaner.delete.retention.ms: 3600000
      # The largest record batch size allowed by Kafka. If this is increased and there are consumers older than 0.10.2,
      # the consumers' fetch size must also be increased so that the they can fetch record batches this large.
      # In the latest message format version, records are always grouped into batches for efficiency. In previous message
      # format versions, uncompressed records are not grouped into batches and this limit only applies to a single record in that case.
      # This can be set per topic with the topic level max.message.bytes config.
      # Default value: 1000012
      message.max.bytes: 52428800
      # SSL Configuration
      ssl.cipher.suites: "TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384"
      ssl.enabled.protocols: "TLSv1.2"
      ssl.protocol: "TLSv1.2"
#    jvmOptions:
#      "-Xms": "1g"
#      "-Xmx": "2g"
    resources:
#      requests:
#        cpu: 500m
#        memory: 4Gi
      limits:
        cpu: 500m
        memory: 1Gi
    storage:
      type: jbod
      volumes:
      - id: 0
        type: persistent-claim
        size: 1Gi
        deleteClaim: false
#      - id: 1
#        type: persistent-claim
#        size: 1Gi
#        deleteClaim: false
  zookeeper:
    replicas: 1
    storage:
      type: persistent-claim
      size: 1Gi
      deleteClaim: false
#    jvmOptions:
#      "-Xms": "2g"
#      "-Xmx": "2g"
    resources:
#      requests:
#        cpu: 500m
#        memory: 3Gi
      limits:
        cpu: 250m
        memory: 512Mi
  entityOperator:
    topicOperator:
      reconciliationIntervalSeconds: 60
      resources:
        requests:
          cpu: 50m
          memory: 64Mi
        limits:
          cpu: 500m
          memory: 768Mi
    userOperator:
      reconciliationIntervalSeconds: 60
      resources:
        requests:
          cpu: 50m
          memory: 64Mi
        limits:
          cpu: 500m
          memory: 768Mi
    tlsSidecar:
      resources:
        requests:
          cpu: 50m
          memory: 64Mi
        limits:
          cpu: 200m
          memory: 256Mi
